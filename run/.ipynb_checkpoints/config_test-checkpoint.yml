random_base: &random_base # base configuration for all random model
  TRAIN_PATH: ../../Data/data/train64_0.mat
  TEST_PATH: ../../Data/data/test64_0.mat
  save_mode: state_dict # None means saving as .pt file (all model); or state_dict for .pkl file(only parameters of model)
  patience: 10 # if there is {patience} epoch that val_error is larger, early stop,
  print_model_flag: False # print model information or not

random_fno_10:
  name: random_fno_10 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 0 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128,128] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 12  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5

random_fno_24:
  name: random_fno_24 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 0 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128,128] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 24  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fno_7:
  name: random_fno_7 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 0 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128,128] # layer of fnn
  layer_num: 7 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fno_5:
  name: random_fno_5 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 0 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128,128] # layer of fnn
  layer_num: 5 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fnn_64:
  name: random_fnn_64 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 7 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,64,64,64] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fnn_256:
  name: random_fnn_256 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 7 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,256,256,256] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fnn_4:
  name: random_fnn_4 # or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 7 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128,128,128] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5
random_fnn_2:
  name: random_fnn_2# or add _normalization to test normalization in freq
  <<: *random_base
  cuda_id: 6 # gpu ids, e.g. 0,1,2,3
  n_out: 4 # rhoxy,phsxy,rhoyx,phsyx
  thre_epoch: 150 # condiser early stop after {thre_epoch} epochs
  s_train: [64,64,64,64] # resolution in (x,y) direction
  r_train: [1,1,1,1] # Interval sampling
  s_test: [64,64,64,64] # resolution in (x,y) direction
  r_test: [1,1,1,1] # Interval sampling
  layer_sizes: [2,128,128] # layer of fnn
  layer_num: 6 # number of fno layer
  last_size: 128 # size of last layer
  modes: 18  # cutoff modes
  width: 32  # width for Linear at first layer
  act_fno : gelu # activation of fno layer
  act_func: tanh
  init_func: xavier_uniform
  ntrain: 2000 # samples of training
  ntest: 3000   # samples of test
  batch_size: 50
  learning_rate: 0.001
  epochs: 300
  save_step: 10 # save model each steps
  step_size: 50 # step size in scheduler
  gamma: 0.5